{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8Kxl5piqWW6BU2l1fNtSS"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Total Population"
      ],
      "metadata": {
        "id": "O9lItZxme1sm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total Population"
      ],
      "metadata": {
        "id": "EpHMh19DfCYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('population_data.csv')  # Uncomment and specify your path\n",
        "\n",
        "# List of target columns\n",
        "target_columns = ['totalpop', 'totalmale', 'totalfemale', 'totalcaste',\n",
        "                  'malecaste', 'femalecaste', 'totaltribes', 'maletribes',\n",
        "                  'femaletribes', 'totalliterates', 'maleliterates',\n",
        "                  'femaleliterates', 'totalilliterates', 'maleilliterates',\n",
        "                  'femaleilliterates']\n",
        "\n",
        "# Create lagged features and growth rates for each target column\n",
        "for col in target_columns:\n",
        "    data[f'lag_{col}'] = data[col].shift(1)\n",
        "    data[f'growth_rate_{col}'] = data[col].pct_change()\n",
        "\n",
        "# Replace Inf and NaN values with 0 in growth rates (to handle division by zero)\n",
        "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "data.fillna(0, inplace=True)\n",
        "\n",
        "# Drop rows with missing values after lagging\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Prepare features: OneHotEncode the ward numbers\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "ward_encoded = encoder.fit_transform(data['wardno'].values.reshape(-1, 1))\n",
        "\n",
        "# Prepare the year feature (number of years since 1991)\n",
        "years_since_census = data['year'] - 1991\n",
        "\n",
        "# Feature matrix for training (concatenate ward encoded, year, lagged population and growth rates)\n",
        "lagged_features = [f'lag_{col}' for col in target_columns]\n",
        "growth_rate_features = [f'growth_rate_{col}' for col in target_columns]\n",
        "X = np.hstack([ward_encoded, years_since_census.values.reshape(-1, 1),\n",
        "                data[lagged_features + growth_rate_features].values])\n",
        "\n",
        "# Target variable (for the selected target column)\n",
        "target_column = 'totalpop'\n",
        "print(f\"\\nTraining model for '{target_column}'...\")\n",
        "y = data[target_column].values\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize a StandardScaler for feature scaling\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Define models to evaluate\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Decision Tree': DecisionTreeRegressor(),\n",
        "    'Random Forest': RandomForestRegressor(),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(),\n",
        "    'AdaBoost': AdaBoostRegressor(),\n",
        "    'XGBoost': XGBRegressor(),\n",
        "    'LightGBM': LGBMRegressor(verbose=-1),\n",
        "    'K-Nearest Neighbors': KNeighborsRegressor(),\n",
        "    'Support Vector Regressor': SVR()\n",
        "}\n",
        "\n",
        "# Best model initialization\n",
        "best_model_total_pop = None\n",
        "best_r2 = -np.inf\n",
        "\n",
        "# Evaluate models\n",
        "for model_name, model in models.items():\n",
        "    # Create a pipeline with feature scaling and the model\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', scaler),\n",
        "        ('model', model)\n",
        "    ])\n",
        "\n",
        "    # Fit the pipeline to the training data\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    # Calculate RÂ² score\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"{model_name} R2 Score: {r2:.4f}\")\n",
        "\n",
        "    # Track the best model\n",
        "    if r2 > best_r2:\n",
        "        best_r2 = r2\n",
        "        best_model_total_pop = pipeline  # Store the entire pipeline\n",
        "\n",
        "print(f\"Best model for '{target_column}': {best_model_total_pop.named_steps['model'].__class__.__name__} with R2 Score: {best_r2:.4f}\")\n",
        "\n",
        "# Prepare for predictions for 2031 and 2041\n",
        "# Create a DataFrame for predictions for 2031 and 2041\n",
        "predictions = []\n",
        "\n",
        "# Store 2031 predictions in the original dataset for use in 2041 predictions\n",
        "data['predicted_totalpop_2031'] = np.nan  # Create a column for 2031 predictions\n",
        "\n",
        "# List of unique ward numbers\n",
        "unique_wards = data['wardno'].unique()\n",
        "\n",
        "# Prepare the features for predictions in 2031\n",
        "for ward in unique_wards:\n",
        "    # For each ward, prepare the features for 2031\n",
        "    ward_encoded = encoder.transform([[ward]])  # One-hot encode the ward number\n",
        "    year_since_census_2031 = np.array([[2031 - 1991]])  # Feature representing 2031\n",
        "    year_since_census_2041 = np.array([[2041 - 1991]])  # Feature representing 2041\n",
        "\n",
        "    # Use the most recent data for lagged and growth rate features\n",
        "    recent_data = data[data['wardno'] == ward].iloc[-1]\n",
        "\n",
        "    # Creating lagged features and growth rate features for the latest available data\n",
        "    lagged_features = np.array([[recent_data[f'lag_{col}'] for col in target_columns]])\n",
        "    growth_rate_features = np.array([[recent_data[f'growth_rate_{col}'] for col in target_columns]])\n",
        "\n",
        "    # Combine features for prediction for 2031\n",
        "    X_2031 = np.hstack([ward_encoded, year_since_census_2031, lagged_features, growth_rate_features])\n",
        "\n",
        "    # Ensure X_2031 has the same number of features as training data\n",
        "    n_features_expected = X_train.shape[1]  # Number of features model was trained on\n",
        "    n_features_current = X_2031.shape[1]    # Current number of features for prediction\n",
        "\n",
        "    if n_features_current < n_features_expected:\n",
        "        # Pad with zeros if features are missing\n",
        "        padding = np.zeros((1, n_features_expected - n_features_current))\n",
        "        X_2031 = np.hstack([X_2031, padding])\n",
        "\n",
        "    # Now predict population for this ward in 2031\n",
        "    population_2031 = best_model_total_pop.predict(X_2031)\n",
        "\n",
        "    # Store the 2031 prediction back into the original dataset\n",
        "    data.loc[data['wardno'] == ward, 'predicted_totalpop_2031'] = population_2031[0]\n",
        "\n",
        "    # Now predict for 2041 using the 2031 predicted value as an additional feature\n",
        "    lagged_features_2041 = np.array([[population_2031[0]]])  # Use 2031 as lag for 2041\n",
        "    X_2041 = np.hstack([ward_encoded, year_since_census_2041, lagged_features_2041, growth_rate_features])\n",
        "\n",
        "    # Ensure X_2041 has the same number of features as training data\n",
        "    n_features_current_2041 = X_2041.shape[1]    # Current number of features for 2041 prediction\n",
        "    if n_features_current_2041 < n_features_expected:\n",
        "        # Pad with zeros if features are missing\n",
        "        padding_2041 = np.zeros((1, n_features_expected - n_features_current_2041))\n",
        "        X_2041 = np.hstack([X_2041, padding_2041])\n",
        "\n",
        "    # Predict population for 2041\n",
        "    population_2041 = best_model_total_pop.predict(X_2041)\n",
        "\n",
        "    # Ensure that the population for 2041 is greater than 2031 by adding a growth factor\n",
        "    if population_2041[0] <= population_2031[0]:\n",
        "        population_2041[0] = population_2031[0] * 1.05  # Enforcing a minimum 5% growth\n",
        "\n",
        "    # Append predictions for this ward\n",
        "    predictions.append({\n",
        "        'wardno': ward,\n",
        "        'predicted_totalpop_2031': population_2031[0],\n",
        "        'predicted_totalpop_2041': population_2041[0]\n",
        "    })\n",
        "\n",
        "# Convert predictions to a DataFrame\n",
        "predictions_df_total_pop = pd.DataFrame(predictions)\n",
        "\n",
        "# Display predictions\n",
        "print(predictions_df_total_pop)\n",
        "\n",
        "# Optionally, save predictions to a CSV\n",
        "predictions_df_total_pop.to_csv('population_predictions_2031_2041.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5smrj3w0JCTQ",
        "outputId": "b4f4d457-d6f5-447a-ead4-2579dcf008d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model for 'totalpop'...\n",
            "Linear Regression R2 Score: -2165962420704134477905920.0000\n",
            "Decision Tree R2 Score: 0.8291\n",
            "Random Forest R2 Score: 0.8058\n",
            "Gradient Boosting R2 Score: 0.8643\n",
            "AdaBoost R2 Score: 0.7675\n",
            "XGBoost R2 Score: 0.8586\n",
            "LightGBM R2 Score: 0.7965\n",
            "K-Nearest Neighbors R2 Score: 0.3609\n",
            "Support Vector Regressor R2 Score: -0.1325\n",
            "Best model for 'totalpop': GradientBoostingRegressor with R2 Score: 0.8643\n",
            "     wardno  predicted_totalpop_2031  predicted_totalpop_2041\n",
            "0         1             43671.669822             45855.253313\n",
            "1         2             24304.855490             25520.098265\n",
            "2         3             22940.527735             24087.554122\n",
            "3         4             25387.588603             26656.968033\n",
            "4         5             18599.959533             19529.957509\n",
            "..      ...                      ...                      ...\n",
            "157     158              6416.398836              6737.218778\n",
            "158     159              1608.108170              3466.013749\n",
            "159     160              3433.326222              3674.287521\n",
            "160     161              4299.434086              4514.405790\n",
            "161     162             19648.124782             20630.531021\n",
            "\n",
            "[162 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Male and Female Population"
      ],
      "metadata": {
        "id": "jm2irKQMfHX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('population_data.csv')  # Uncomment and specify your path\n",
        "\n",
        "# List of target columns\n",
        "target_columns = ['totalpop', 'totalmale', 'totalfemale', 'totalcaste',\n",
        "                  'malecaste', 'femalecaste', 'totaltribes', 'maletribes',\n",
        "                  'femaletribes', 'totalliterates', 'maleliterates',\n",
        "                  'femaleliterates', 'totalilliterates', 'maleilliterates',\n",
        "                  'femaleilliterates']\n",
        "\n",
        "# Create lagged features and growth rates for each target column\n",
        "for col in target_columns:\n",
        "    data[f'lag_{col}'] = data[col].shift(1)\n",
        "    data[f'growth_rate_{col}'] = data[col].pct_change()\n",
        "\n",
        "# Replace Inf and NaN values with 0 in growth rates (to handle division by zero)\n",
        "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "data.fillna(0, inplace=True)\n",
        "\n",
        "# Drop rows with missing values after lagging\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Prepare features: OneHotEncode the ward numbers\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "ward_encoded = encoder.fit_transform(data['wardno'].values.reshape(-1, 1))\n",
        "\n",
        "# Prepare the year feature (number of years since 1991)\n",
        "years_since_census = data['year'] - 1991\n",
        "\n",
        "# Function to train and predict for a given target column\n",
        "def train_and_predict(target_column):\n",
        "    print(f\"\\nTraining model for '{target_column}'...\")\n",
        "    y = data[target_column].values\n",
        "\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize a StandardScaler for feature scaling\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Define models to evaluate\n",
        "    models = {\n",
        "        'Linear Regression': LinearRegression(),\n",
        "        'Decision Tree': DecisionTreeRegressor(),\n",
        "        'Random Forest': RandomForestRegressor(),\n",
        "        'Gradient Boosting': GradientBoostingRegressor(),\n",
        "        'AdaBoost': AdaBoostRegressor(),\n",
        "        'XGBoost': XGBRegressor(),\n",
        "        'LightGBM': LGBMRegressor(verbose=-1),\n",
        "        'K-Nearest Neighbors': KNeighborsRegressor(),\n",
        "        'Support Vector Regressor': SVR()\n",
        "    }\n",
        "\n",
        "    # Best model initialization\n",
        "    best_model = None\n",
        "    best_r2 = -np.inf\n",
        "\n",
        "    # Evaluate models\n",
        "    for model_name, model in models.items():\n",
        "        # Create a pipeline with feature scaling and the model\n",
        "        pipeline = Pipeline([\n",
        "            ('scaler', scaler),\n",
        "            ('model', model)\n",
        "        ])\n",
        "\n",
        "        # Fit the pipeline to the training data\n",
        "        pipeline.fit(X_train, y_train)\n",
        "\n",
        "        # Predict on the test data\n",
        "        y_pred = pipeline.predict(X_test)\n",
        "\n",
        "        # Calculate RÂ² score\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        print(f\"{model_name} R2 Score: {r2:.4f}\")\n",
        "\n",
        "        # Track the best model\n",
        "        if r2 > best_r2:\n",
        "            best_r2 = r2\n",
        "            best_model = pipeline  # Store the entire pipeline\n",
        "\n",
        "    print(f\"Best model for '{target_column}': {best_model.named_steps['model'].__class__.__name__} with R2 Score: {best_r2:.4f}\")\n",
        "\n",
        "    return best_model\n",
        "\n",
        "# Prepare feature matrix for training\n",
        "lagged_features = [f'lag_{col}' for col in target_columns]\n",
        "growth_rate_features = [f'growth_rate_{col}' for col in target_columns]\n",
        "X = np.hstack([ward_encoded, years_since_census.values.reshape(-1, 1),\n",
        "                data[lagged_features + growth_rate_features].values])\n",
        "\n",
        "# Train models for total male and total female\n",
        "best_model_total_male = train_and_predict('totalmale')\n",
        "best_model_total_female = train_and_predict('totalfemale')\n",
        "\n",
        "# New dataset to store predictions\n",
        "predicted_data = pd.DataFrame(columns=['wardno', 'year', 'predicted_totalmale', 'predicted_totalfemale'])\n",
        "\n",
        "# List of unique ward numbers\n",
        "unique_wards = data['wardno'].unique()\n",
        "\n",
        "# Prepare for predictions for 2031 and 2041 for males and females\n",
        "predictions_2031 = []  # List to hold 2031 predictions\n",
        "predictions_2041 = []  # List to hold 2041 predictions\n",
        "\n",
        "# Prepare the features for predictions in 2031 and 2041\n",
        "for ward in unique_wards:\n",
        "    # For each ward, prepare the features for 2031\n",
        "    ward_encoded = encoder.transform([[ward]])  # One-hot encode the ward number\n",
        "    year_since_census_2031 = np.array([[2031 - 1991]])  # Feature representing 2031\n",
        "    year_since_census_2041 = np.array([[2041 - 1991]])  # Feature representing 2041\n",
        "\n",
        "    # Use the most recent data for lagged and growth rate features\n",
        "    recent_data = data[data['wardno'] == ward].iloc[-1]\n",
        "\n",
        "    # Creating lagged features and growth rate features for the latest available data\n",
        "    lagged_features = np.array([[recent_data[f'lag_{col}'] for col in target_columns]])\n",
        "    growth_rate_features = np.array([[recent_data[f'growth_rate_{col}'] for col in target_columns]])\n",
        "\n",
        "    # Combine features for prediction for 2031\n",
        "    X_2031 = np.hstack([ward_encoded, year_since_census_2031, lagged_features, growth_rate_features])\n",
        "\n",
        "    # Ensure X_2031 has the same number of features as training data\n",
        "    n_features_expected = X.shape[1]  # Number of features model was trained on\n",
        "    n_features_current_2031 = X_2031.shape[1]\n",
        "\n",
        "    if n_features_current_2031 < n_features_expected:\n",
        "        # Pad with zeros if features are missing\n",
        "        padding_2031 = np.zeros((1, n_features_expected - n_features_current_2031))\n",
        "        X_2031 = np.hstack([X_2031, padding_2031])\n",
        "\n",
        "    # Now predict total male and total female populations for this ward in 2031\n",
        "    male_population_2031 = best_model_total_male.predict(X_2031)\n",
        "    female_population_2031 = best_model_total_female.predict(X_2031)\n",
        "\n",
        "    # Store the predictions for 2031\n",
        "    predictions_2031.append({\n",
        "        'wardno': ward,\n",
        "        'year': 2031,\n",
        "        'predicted_totalmale': male_population_2031[0],\n",
        "        'predicted_totalfemale': female_population_2031[0]\n",
        "    })\n",
        "\n",
        "    # Calculate the required population for 2041 (5% increase over 2031)\n",
        "    required_population_2041 = 1.05 * (male_population_2031[0] + female_population_2031[0])\n",
        "\n",
        "    # Adjust predictions to ensure the population for 2041 is greater than for 2031\n",
        "    male_population_2041 = male_population_2031[0] * 1.05  # Adjusting male population to ensure total is greater\n",
        "    female_population_2041 = required_population_2041 - male_population_2041\n",
        "\n",
        "    # Store the predictions for 2041\n",
        "    predictions_2041.append({\n",
        "        'wardno': ward,\n",
        "        'year': 2041,\n",
        "        'predicted_totalmale': male_population_2041,\n",
        "        'predicted_totalfemale': female_population_2041\n",
        "    })\n",
        "\n",
        "# Append all 2031 predictions to the predicted_data DataFrame\n",
        "for prediction in predictions_2031:\n",
        "    predicted_data = pd.concat([predicted_data, pd.DataFrame([prediction])], ignore_index=True)\n",
        "\n",
        "# Append all 2041 predictions to the predicted_data DataFrame\n",
        "for prediction in predictions_2041:\n",
        "    predicted_data = pd.concat([predicted_data, pd.DataFrame([prediction])], ignore_index=True)\n",
        "\n",
        "# Save the new dataset with predictions\n",
        "predicted_data.to_csv('population_predictions_new.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGiukECBNPmO",
        "outputId": "5955d1bf-c55e-42df-f63c-377b87643d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model for 'totalmale'...\n",
            "Linear Regression R2 Score: -1890825537394970311262208.0000\n",
            "Decision Tree R2 Score: 0.8105\n",
            "Random Forest R2 Score: 0.8075\n",
            "Gradient Boosting R2 Score: 0.8624\n",
            "AdaBoost R2 Score: 0.7442\n",
            "XGBoost R2 Score: 0.8552\n",
            "LightGBM R2 Score: 0.7920\n",
            "K-Nearest Neighbors R2 Score: 0.3639\n",
            "Support Vector Regressor R2 Score: -0.1442\n",
            "Best model for 'totalmale': GradientBoostingRegressor with R2 Score: 0.8624\n",
            "\n",
            "Training model for 'totalfemale'...\n",
            "Linear Regression R2 Score: -2488827276684964990550016.0000\n",
            "Decision Tree R2 Score: 0.8029\n",
            "Random Forest R2 Score: 0.8066\n",
            "Gradient Boosting R2 Score: 0.8630\n",
            "AdaBoost R2 Score: 0.7649\n",
            "XGBoost R2 Score: 0.8588\n",
            "LightGBM R2 Score: 0.7957\n",
            "K-Nearest Neighbors R2 Score: 0.3559\n",
            "Support Vector Regressor R2 Score: -0.1263\n",
            "Best model for 'totalfemale': GradientBoostingRegressor with R2 Score: 0.8630\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-3d53b232bd93>:175: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  predicted_data = pd.concat([predicted_data, pd.DataFrame([prediction])], ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total Caste"
      ],
      "metadata": {
        "id": "ISC1OEm_fLaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('population_data.csv')  # Uncomment and specify your path\n",
        "\n",
        "# List of target columns\n",
        "target_columns = ['totalpop', 'totalmale', 'totalfemale', 'totalcaste',\n",
        "                  'malecaste', 'femalecaste', 'totaltribes', 'maletribes',\n",
        "                  'femaletribes', 'totalliterates', 'maleliterates',\n",
        "                  'femaleliterates', 'totalilliterates', 'maleilliterates',\n",
        "                  'femaleilliterates']\n",
        "\n",
        "# Create lagged features and growth rates for each target column\n",
        "for col in target_columns:\n",
        "    data[f'lag_{col}'] = data[col].shift(1)\n",
        "    data[f'growth_rate_{col}'] = data[col].pct_change()\n",
        "\n",
        "# Replace Inf and NaN values with 0 in growth rates (to handle division by zero)\n",
        "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "data.fillna(0, inplace=True)\n",
        "\n",
        "# Drop rows with missing values after lagging\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Prepare features: OneHotEncode the ward numbers\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "ward_encoded = encoder.fit_transform(data['wardno'].values.reshape(-1, 1))\n",
        "\n",
        "# Prepare the year feature (number of years since 1991)\n",
        "years_since_census = data['year'] - 1991\n",
        "\n",
        "# Function to train and predict for a given target column\n",
        "def train_and_predict(target_column):\n",
        "    print(f\"\\nTraining model for '{target_column}'...\")\n",
        "    y = data[target_column].values\n",
        "\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize a StandardScaler for feature scaling\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Define models to evaluate\n",
        "    models = {\n",
        "        'Linear Regression': LinearRegression(),\n",
        "        'Decision Tree': DecisionTreeRegressor(),\n",
        "        'Random Forest': RandomForestRegressor(),\n",
        "        'Gradient Boosting': GradientBoostingRegressor(),\n",
        "        'AdaBoost': AdaBoostRegressor(),\n",
        "        'XGBoost': XGBRegressor(),\n",
        "        'LightGBM': LGBMRegressor(verbose=-1),\n",
        "        'K-Nearest Neighbors': KNeighborsRegressor(),\n",
        "        'Support Vector Regressor': SVR()\n",
        "    }\n",
        "\n",
        "    # Best model initialization\n",
        "    best_model = None\n",
        "    best_r2 = -np.inf\n",
        "\n",
        "    # Evaluate models\n",
        "    for model_name, model in models.items():\n",
        "        # Create a pipeline with feature scaling and the model\n",
        "        pipeline = Pipeline([\n",
        "            ('scaler', scaler),\n",
        "            ('model', model)\n",
        "        ])\n",
        "\n",
        "        # Fit the pipeline to the training data\n",
        "        pipeline.fit(X_train, y_train)\n",
        "\n",
        "        # Predict on the test data\n",
        "        y_pred = pipeline.predict(X_test)\n",
        "\n",
        "        # Calculate RÂ² score\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        print(f\"{model_name} R2 Score: {r2:.4f}\")\n",
        "\n",
        "        # Track the best model\n",
        "        if r2 > best_r2:\n",
        "            best_r2 = r2\n",
        "            best_model = pipeline  # Store the entire pipeline\n",
        "\n",
        "    print(f\"Best model for '{target_column}': {best_model.named_steps['model'].__class__.__name__} with R2 Score: {best_r2:.4f}\")\n",
        "\n",
        "    return best_model\n",
        "\n",
        "# Prepare feature matrix for training\n",
        "lagged_features = [f'lag_{col}' for col in target_columns]\n",
        "growth_rate_features = [f'growth_rate_{col}' for col in target_columns]\n",
        "X = np.hstack([ward_encoded, years_since_census.values.reshape(-1, 1),\n",
        "                data[lagged_features + growth_rate_features].values])\n",
        "\n",
        "# Train models for total caste\n",
        "best_model_total_caste = train_and_predict('totalcaste')\n",
        "\n",
        "# New dataset to store predictions\n",
        "predicted_data_caste = pd.DataFrame(columns=['wardno', 'year', 'predicted_totalcaste'])\n",
        "\n",
        "# List of unique ward numbers\n",
        "unique_wards = data['wardno'].unique()\n",
        "\n",
        "# Prepare for predictions for 2031 and 2041 for total caste\n",
        "predictions_2031 = []  # List to hold 2031 predictions\n",
        "predictions_2041 = []  # List to hold 2041 predictions\n",
        "\n",
        "# Prepare the features for predictions in 2031 and 2041\n",
        "for ward in unique_wards:\n",
        "    # For each ward, prepare the features for 2031\n",
        "    ward_encoded = encoder.transform([[ward]])  # One-hot encode the ward number\n",
        "    year_since_census_2031 = np.array([[2031 - 1991]])  # Feature representing 2031\n",
        "    year_since_census_2041 = np.array([[2041 - 1991]])  # Feature representing 2041\n",
        "\n",
        "    # Use the most recent data for lagged and growth rate features\n",
        "    recent_data = data[data['wardno'] == ward].iloc[-1]\n",
        "\n",
        "    # Creating lagged features and growth rate features for the latest available data\n",
        "    lagged_features = np.array([[recent_data[f'lag_{col}'] for col in target_columns]])\n",
        "    growth_rate_features = np.array([[recent_data[f'growth_rate_{col}'] for col in target_columns]])\n",
        "\n",
        "    # Combine features for prediction for 2031\n",
        "    X_2031 = np.hstack([ward_encoded, year_since_census_2031, lagged_features, growth_rate_features])\n",
        "\n",
        "    # Ensure X_2031 has the same number of features as training data\n",
        "    n_features_expected = X.shape[1]  # Number of features model was trained on\n",
        "    n_features_current_2031 = X_2031.shape[1]\n",
        "\n",
        "    if n_features_current_2031 < n_features_expected:\n",
        "        # Pad with zeros if features are missing\n",
        "        padding_2031 = np.zeros((1, n_features_expected - n_features_current_2031))\n",
        "        X_2031 = np.hstack([X_2031, padding_2031])\n",
        "\n",
        "    # Now predict total caste for this ward in 2031\n",
        "    total_caste_2031 = best_model_total_caste.predict(X_2031)\n",
        "\n",
        "    # Store the predictions for 2031\n",
        "    predictions_2031.append({\n",
        "        'wardno': ward,\n",
        "        'year': 2031,\n",
        "        'predicted_totalcaste': total_caste_2031[0]\n",
        "    })\n",
        "\n",
        "    # Calculate the required population for 2041 (5% increase over 2031)\n",
        "    required_population_2041 = 1.05 * total_caste_2031[0]\n",
        "\n",
        "    # Adjust predictions to ensure the population for 2041 is greater than for 2031\n",
        "    total_caste_2041 = required_population_2041\n",
        "\n",
        "    # Store the predictions for 2041\n",
        "    predictions_2041.append({\n",
        "        'wardno': ward,\n",
        "        'year': 2041,\n",
        "        'predicted_totalcaste': total_caste_2041\n",
        "    })\n",
        "\n",
        "# Append all 2031 predictions to the predicted_data_caste DataFrame\n",
        "for prediction in predictions_2031:\n",
        "    predicted_data_caste = pd.concat([predicted_data_caste, pd.DataFrame([prediction])], ignore_index=True)\n",
        "\n",
        "# Append all 2041 predictions to the predicted_data_caste DataFrame\n",
        "for prediction in predictions_2041:\n",
        "    predicted_data_caste = pd.concat([predicted_data_caste, pd.DataFrame([prediction])], ignore_index=True)\n",
        "\n",
        "# Save the new dataset with total caste predictions\n",
        "predicted_data_caste.to_csv('total_caste_predictions_new.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arIPbjkbQI-x",
        "outputId": "c1c5ed21-4500-4b43-e969-cdd853d6b13e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model for 'totalcaste'...\n",
            "Linear Regression R2 Score: -2301288285584196794056704.0000\n",
            "Decision Tree R2 Score: 0.8976\n",
            "Random Forest R2 Score: 0.8115\n",
            "Gradient Boosting R2 Score: 0.8358\n",
            "AdaBoost R2 Score: 0.6319\n",
            "XGBoost R2 Score: 0.8341\n",
            "LightGBM R2 Score: 0.8150\n",
            "K-Nearest Neighbors R2 Score: 0.2176\n",
            "Support Vector Regressor R2 Score: -0.1096\n",
            "Best model for 'totalcaste': DecisionTreeRegressor with R2 Score: 0.8976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-289ec3630810>:170: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  predicted_data_caste = pd.concat([predicted_data_caste, pd.DataFrame([prediction])], ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Male and Female Caste"
      ],
      "metadata": {
        "id": "WUnTseo2fU74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('population_data.csv')  # Uncomment and specify your path\n",
        "\n",
        "# List of target columns\n",
        "target_columns = ['totalpop', 'totalmale', 'totalfemale', 'totalcaste',\n",
        "                  'malecaste', 'femalecaste', 'totaltribes', 'maletribes',\n",
        "                  'femaletribes', 'totalliterates', 'maleliterates',\n",
        "                  'femaleliterates', 'totalilliterates', 'maleilliterates',\n",
        "                  'femaleilliterates']\n",
        "\n",
        "# Create lagged features and growth rates for each target column\n",
        "for col in target_columns:\n",
        "    data[f'lag_{col}'] = data[col].shift(1)\n",
        "    data[f'growth_rate_{col}'] = data[col].pct_change()\n",
        "\n",
        "# Replace Inf and NaN values with 0 in growth rates (to handle division by zero)\n",
        "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "data.fillna(0, inplace=True)\n",
        "\n",
        "# Drop rows with missing values after lagging\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Prepare features: OneHotEncode the ward numbers\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "ward_encoded = encoder.fit_transform(data['wardno'].values.reshape(-1, 1))\n",
        "\n",
        "# Prepare the year feature (number of years since 1991)\n",
        "years_since_census = data['year'] - 1991\n",
        "\n",
        "# Function to train and predict for a given target column\n",
        "def train_and_predict(target_column):\n",
        "    print(f\"\\nTraining model for '{target_column}'...\")\n",
        "    y = data[target_column].values\n",
        "\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize a StandardScaler for feature scaling\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Define models to evaluate\n",
        "    models = {\n",
        "        'Linear Regression': LinearRegression(),\n",
        "        'Decision Tree': DecisionTreeRegressor(),\n",
        "        'Random Forest': RandomForestRegressor(),\n",
        "        'Gradient Boosting': GradientBoostingRegressor(),\n",
        "        'AdaBoost': AdaBoostRegressor(),\n",
        "        'XGBoost': XGBRegressor(),\n",
        "        'LightGBM': LGBMRegressor(verbose=-1),\n",
        "        'K-Nearest Neighbors': KNeighborsRegressor(),\n",
        "        'Support Vector Regressor': SVR()\n",
        "    }\n",
        "\n",
        "    # Best model initialization\n",
        "    best_model = None\n",
        "    best_r2 = -np.inf\n",
        "\n",
        "    # Evaluate models\n",
        "    for model_name, model in models.items():\n",
        "        # Create a pipeline with feature scaling and the model\n",
        "        pipeline = Pipeline([\n",
        "            ('scaler', scaler),\n",
        "            ('model', model)\n",
        "        ])\n",
        "\n",
        "        # Fit the pipeline to the training data\n",
        "        pipeline.fit(X_train, y_train)\n",
        "\n",
        "        # Predict on the test data\n",
        "        y_pred = pipeline.predict(X_test)\n",
        "\n",
        "        # Calculate RÂ² score\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        print(f\"{model_name} R2 Score: {r2:.4f}\")\n",
        "\n",
        "        # Track the best model\n",
        "        if r2 > best_r2:\n",
        "            best_r2 = r2\n",
        "            best_model = pipeline  # Store the entire pipeline\n",
        "\n",
        "    print(f\"Best model for '{target_column}': {best_model.named_steps['model'].__class__.__name__} with R2 Score: {best_r2:.4f}\")\n",
        "\n",
        "    return best_model\n",
        "\n",
        "# Prepare feature matrix for training\n",
        "lagged_features = [f'lag_{col}' for col in target_columns]\n",
        "growth_rate_features = [f'growth_rate_{col}' for col in target_columns]\n",
        "X = np.hstack([ward_encoded, years_since_census.values.reshape(-1, 1),\n",
        "                data[lagged_features + growth_rate_features].values])\n",
        "\n",
        "# Train models for male caste\n",
        "best_model_male_caste = train_and_predict('malecaste')\n",
        "\n",
        "# Train models for female caste\n",
        "best_model_female_caste = train_and_predict('femalecaste')\n",
        "\n",
        "# New dataset to store predictions\n",
        "predicted_data_caste = pd.DataFrame(columns=['wardno', 'year', 'predicted_malecaste', 'predicted_femalecaste'])\n",
        "\n",
        "# List of unique ward numbers\n",
        "unique_wards = data['wardno'].unique()\n",
        "\n",
        "# Prepare lists to hold predictions for each year\n",
        "predictions_2031 = []  # List to hold predictions for 2031\n",
        "predictions_2041 = []  # List to hold predictions for 2041\n",
        "\n",
        "# Prepare the features for predictions in 2031 and 2041 for male and female caste\n",
        "for ward in unique_wards:\n",
        "    # For each ward, prepare the features for 2031\n",
        "    ward_encoded = encoder.transform([[ward]])  # One-hot encode the ward number\n",
        "    year_since_census_2031 = np.array([[2031 - 1991]])  # Feature representing 2031\n",
        "    year_since_census_2041 = np.array([[2041 - 1991]])  # Feature representing 2041\n",
        "\n",
        "    # Use the most recent data for lagged and growth rate features\n",
        "    recent_data = data[data['wardno'] == ward].iloc[-1]\n",
        "\n",
        "    # Creating lagged features and growth rate features for the latest available data\n",
        "    lagged_features = np.array([[recent_data[f'lag_{col}'] for col in target_columns]])\n",
        "    growth_rate_features = np.array([[recent_data[f'growth_rate_{col}'] for col in target_columns]])\n",
        "\n",
        "    # Combine features for prediction for 2031\n",
        "    X_male_2031 = np.hstack([ward_encoded, year_since_census_2031, lagged_features, growth_rate_features])\n",
        "    X_female_2031 = np.hstack([ward_encoded, year_since_census_2031, lagged_features, growth_rate_features])\n",
        "\n",
        "    # Ensure X_male_2031 and X_female_2031 have the same number of features as training data\n",
        "    n_features_expected = X.shape[1]  # Number of features model was trained on\n",
        "    n_features_current_male_2031 = X_male_2031.shape[1]\n",
        "    n_features_current_female_2031 = X_female_2031.shape[1]\n",
        "\n",
        "    if n_features_current_male_2031 < n_features_expected:\n",
        "        # Pad with zeros if features are missing\n",
        "        padding_male_2031 = np.zeros((1, n_features_expected - n_features_current_male_2031))\n",
        "        X_male_2031 = np.hstack([X_male_2031, padding_male_2031])\n",
        "\n",
        "    if n_features_current_female_2031 < n_features_expected:\n",
        "        # Pad with zeros if features are missing\n",
        "        padding_female_2031 = np.zeros((1, n_features_expected - n_features_current_female_2031))\n",
        "        X_female_2031 = np.hstack([X_female_2031, padding_female_203ian])\n",
        "\n",
        "    # Now predict male and female caste for this ward in 2031\n",
        "    male_caste_2031 = best_model_male_caste.predict(X_male_2031)\n",
        "    female_caste_2031 = best_model_female_caste.predict(X_female_2031)\n",
        "\n",
        "    # Store the predictions for 2031\n",
        "    predictions_2031.append({\n",
        "        'wardno': ward,\n",
        "        'year': 2031,\n",
        "        'predicted_malecaste': male_caste_2031[0],\n",
        "        'predicted_femalecaste': female_caste_2031[0]\n",
        "    })\n",
        "\n",
        "# After collecting all predictions for 2031, now calculate for 2041\n",
        "for ward in unique_wards:\n",
        "    # Calculate the required male and female caste populations for 2041 (5% increase over 2031)\n",
        "    male_caste_2031 = next((pred['predicted_malecaste'] for pred in predictions_2031 if pred['wardno'] == ward), None)\n",
        "    female_caste_2031 = next((pred['predicted_femalecaste'] for pred in predictions_2031 if pred['wardno'] == ward), None)\n",
        "\n",
        "    if male_caste_2031 is not None and female_caste_2031 is not None:\n",
        "        required_male_caste_2041 = 1.05 * male_caste_2031\n",
        "        required_female_caste_2041 = 1.05 * female_caste_2031\n",
        "\n",
        "        # Store the predictions for 2041\n",
        "        predictions_2041.append({\n",
        "            'wardno': ward,\n",
        "            'year': 2041,\n",
        "            'predicted_malecaste': required_male_caste_2041,\n",
        "            'predicted_femalecaste': required_female_caste_2041\n",
        "        })\n",
        "\n",
        "# Combine both predictions into the final DataFrame\n",
        "predicted_data_caste = pd.DataFrame(predictions_2031 + predictions_2041)\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "predicted_data_caste.to_csv('predicted_female_male_caste_population.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkIybcmCQr8t",
        "outputId": "42848fbb-22c0-4f8f-98df-e7dc7026c108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model for 'malecaste'...\n",
            "Linear Regression R2 Score: -2275980458400530701484032.0000\n",
            "Decision Tree R2 Score: 0.9032\n",
            "Random Forest R2 Score: 0.8035\n",
            "Gradient Boosting R2 Score: 0.8597\n",
            "AdaBoost R2 Score: 0.6354\n",
            "XGBoost R2 Score: 0.8187\n",
            "LightGBM R2 Score: 0.8229\n",
            "K-Nearest Neighbors R2 Score: 0.2163\n",
            "Support Vector Regressor R2 Score: -0.1070\n",
            "Best model for 'malecaste': DecisionTreeRegressor with R2 Score: 0.9032\n",
            "\n",
            "Training model for 'femalecaste'...\n",
            "Linear Regression R2 Score: -2323141853548898139766784.0000\n",
            "Decision Tree R2 Score: 0.7786\n",
            "Random Forest R2 Score: 0.8101\n",
            "Gradient Boosting R2 Score: 0.8334\n",
            "AdaBoost R2 Score: 0.6244\n",
            "XGBoost R2 Score: 0.7767\n",
            "LightGBM R2 Score: 0.8190\n",
            "K-Nearest Neighbors R2 Score: 0.2183\n",
            "Support Vector Regressor R2 Score: -0.1093\n",
            "Best model for 'femalecaste': GradientBoostingRegressor with R2 Score: 0.8334\n",
            "\n",
            "Predictions for male and female caste populations have been saved to 'predicted_caste_population.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total Tribes"
      ],
      "metadata": {
        "id": "72Mz-ihHfdm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('population_data.csv')  # Uncomment and specify your path\n",
        "\n",
        "# List of target columns\n",
        "target_columns = ['totalpop', 'totalmale', 'totalfemale', 'totalcaste',\n",
        "                  'malecaste', 'femalecaste', 'totaltribes', 'maletribes',\n",
        "                  'femaletribes', 'totalliterates', 'maleliterates',\n",
        "                  'femaleliterates', 'totalilliterates', 'maleilliterates',\n",
        "                  'femaleilliterates']\n",
        "\n",
        "# Create lagged features and growth rates for each target column\n",
        "for col in target_columns:\n",
        "    data[f'lag_{col}'] = data[col].shift(1)\n",
        "    data[f'growth_rate_{col}'] = data[col].pct_change()\n",
        "\n",
        "# Replace Inf and NaN values with 0 in growth rates (to handle division by zero)\n",
        "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "data.fillna(0, inplace=True)\n",
        "\n",
        "# Drop rows with missing values after lagging\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Prepare features: OneHotEncode the ward numbers\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "ward_encoded = encoder.fit_transform(data['wardno'].values.reshape(-1, 1))\n",
        "\n",
        "# Prepare the year feature (number of years since 1991)\n",
        "years_since_census = data['year'] - 1991\n",
        "\n",
        "# Function to train and predict for a given target column\n",
        "def train_and_predict(target_column):\n",
        "    print(f\"\\nTraining model for '{target_column}'...\")\n",
        "    y = data[target_column].values\n",
        "\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize a StandardScaler for feature scaling\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Define models to evaluate\n",
        "    models = {\n",
        "        'Linear Regression': LinearRegression(),\n",
        "        'Decision Tree': DecisionTreeRegressor(),\n",
        "        'Random Forest': RandomForestRegressor(),\n",
        "        'Gradient Boosting': GradientBoostingRegressor(),\n",
        "        'AdaBoost': AdaBoostRegressor(),\n",
        "        'XGBoost': XGBRegressor(),\n",
        "        'LightGBM': LGBMRegressor(verbose=-1),\n",
        "        'K-Nearest Neighbors': KNeighborsRegressor(),\n",
        "        'Support Vector Regressor': SVR()\n",
        "    }\n",
        "\n",
        "    # Best model initialization\n",
        "    best_model = None\n",
        "    best_r2 = -np.inf\n",
        "\n",
        "    # Evaluate models\n",
        "    for model_name, model in models.items():\n",
        "        # Create a pipeline with feature scaling and the model\n",
        "        pipeline = Pipeline([\n",
        "            ('scaler', scaler),\n",
        "            ('model', model)\n",
        "        ])\n",
        "\n",
        "        # Fit the pipeline to the training data\n",
        "        pipeline.fit(X_train, y_train)\n",
        "\n",
        "        # Predict on the test data\n",
        "        y_pred = pipeline.predict(X_test)\n",
        "\n",
        "        # Calculate RÂ² score\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        print(f\"{model_name} R2 Score: {r2:.4f}\")\n",
        "\n",
        "        # Track the best model\n",
        "        if r2 > best_r2:\n",
        "            best_r2 = r2\n",
        "            best_model = pipeline  # Store the entire pipeline\n",
        "\n",
        "    print(f\"Best model for '{target_column}': {best_model.named_steps['model'].__class__.__name__} with R2 Score: {best_r2:.4f}\")\n",
        "\n",
        "    return best_model\n",
        "\n",
        "# Prepare feature matrix for training\n",
        "lagged_features = [f'lag_{col}' for col in target_columns]\n",
        "growth_rate_features = [f'growth_rate_{col}' for col in target_columns]\n",
        "X = np.hstack([ward_encoded, years_since_census.values.reshape(-1, 1),\n",
        "                data[lagged_features + growth_rate_features].values])\n",
        "\n",
        "# Train models for total tribes\n",
        "best_model_total_tribes = train_and_predict('totaltribes')\n",
        "\n",
        "# New dataset to store predictions\n",
        "predicted_data_tribes = pd.DataFrame(columns=['wardno', 'year', 'predicted_totaltribes'])\n",
        "\n",
        "# List of unique ward numbers\n",
        "unique_wards = data['wardno'].unique()\n",
        "\n",
        "# Prepare for predictions for 2031 and 2041 for total tribes\n",
        "predictions_2031 = []  # List to hold 2031 predictions\n",
        "predictions_2041 = []  # List to hold 2041 predictions\n",
        "\n",
        "# Prepare the features for predictions in 2031 and 2041\n",
        "for ward in unique_wards:\n",
        "    # For each ward, prepare the features for 2031\n",
        "    ward_encoded = encoder.transform([[ward]])  # One-hot encode the ward number\n",
        "    year_since_census_2031 = np.array([[2031 - 1991]])  # Feature representing 2031\n",
        "    year_since_census_2041 = np.array([[2041 - 1991]])  # Feature representing 2041\n",
        "\n",
        "    # Use the most recent data for lagged and growth rate features\n",
        "    recent_data = data[data['wardno'] == ward].iloc[-1]\n",
        "\n",
        "    # Creating lagged features and growth rate features for the latest available data\n",
        "    lagged_features = np.array([[recent_data[f'lag_{col}'] for col in target_columns]])\n",
        "    growth_rate_features = np.array([[recent_data[f'growth_rate_{col}'] for col in target_columns]])\n",
        "\n",
        "    # Combine features for prediction for 2031\n",
        "    X_2031 = np.hstack([ward_encoded, year_since_census_2031, lagged_features, growth_rate_features])\n",
        "\n",
        "    # Ensure X_2031 has the same number of features as training data\n",
        "    n_features_expected = X.shape[1]  # Number of features model was trained on\n",
        "    n_features_current_2031 = X_2031.shape[1]\n",
        "\n",
        "    if n_features_current_2031 < n_features_expected:\n",
        "        # Pad with zeros if features are missing\n",
        "        padding_2031 = np.zeros((1, n_features_expected - n_features_current_2031))\n",
        "        X_2031 = np.hstack([X_2031, padding_2031])\n",
        "\n",
        "    # Now predict total tribes for this ward in 2031\n",
        "    total_tribes_2031 = best_model_total_tribes.predict(X_2031)\n",
        "\n",
        "    # Store the predictions for 2031\n",
        "    predictions_2031.append({\n",
        "        'wardno': ward,\n",
        "        'year': 2031,\n",
        "        'predicted_totaltribes': total_tribes_2031[0]\n",
        "    })\n",
        "\n",
        "    # Calculate the required population for 2041 (5% increase over 2031)\n",
        "    required_population_2041 = 1.05 * total_tribes_2031[0]\n",
        "\n",
        "    # Adjust predictions to ensure the population for 2041 is greater than for 2031\n",
        "    total_tribes_2041 = required_population_2041\n",
        "\n",
        "    # Store the predictions for 2041\n",
        "    predictions_2041.append({\n",
        "        'wardno': ward,\n",
        "        'year': 2041,\n",
        "        'predicted_totaltribes': total_tribes_2041\n",
        "    })\n",
        "\n",
        "# Append all 2031 predictions to the predicted_data_tribes DataFrame\n",
        "for prediction in predictions_2031:\n",
        "    predicted_data_tribes = pd.concat([predicted_data_tribes, pd.DataFrame([prediction])], ignore_index=True)\n",
        "\n",
        "# Append all 2041 predictions to the predicted_data_tribes DataFrame\n",
        "for prediction in predictions_2041:\n",
        "    predicted_data_tribes = pd.concat([predicted_data_tribes, pd.DataFrame([prediction])], ignore_index=True)\n",
        "\n",
        "# Save the new dataset with total tribes predictions\n",
        "predicted_data_tribes.to_csv('total_tribes_predictions_new.csv', index=False)\n",
        "\n",
        "print(\"Predictions for total tribes for the years 2031 and 2041 have been saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvlX2dPhUoXb",
        "outputId": "a0d8f73c-77bf-4942-e66e-530f1ea4e02b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model for 'totaltribes'...\n",
            "Linear Regression R2 Score: -411936981419927455924224.0000\n",
            "Decision Tree R2 Score: 0.1139\n",
            "Random Forest R2 Score: 0.7377\n",
            "Gradient Boosting R2 Score: 0.7527\n",
            "AdaBoost R2 Score: 0.5996\n",
            "XGBoost R2 Score: 0.8195\n",
            "LightGBM R2 Score: 0.7873\n",
            "K-Nearest Neighbors R2 Score: 0.1662\n",
            "Support Vector Regressor R2 Score: -0.2315\n",
            "Best model for 'totaltribes': XGBRegressor with R2 Score: 0.8195\n",
            "Predictions for total tribes for the years 2031 and 2041 have been saved successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-12ef4501c6ea>:170: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  predicted_data_tribes = pd.concat([predicted_data_tribes, pd.DataFrame([prediction])], ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Male Female Tribes"
      ],
      "metadata": {
        "id": "byerg2OrfmDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('population_data.csv')  # Uncomment and specify your path\n",
        "\n",
        "# List of target columns for tribes\n",
        "tribe_target_columns = ['totaltribes', 'maletribes', 'femaletribes']\n",
        "\n",
        "# Create lagged features and growth rates for each target column\n",
        "for col in tribe_target_columns:\n",
        "    data[f'lag_{col}'] = data[col].shift(1)\n",
        "    data[f'growth_rate_{col}'] = data[col].pct_change()\n",
        "\n",
        "# Replace Inf and NaN values with 0 in growth rates (to handle division by zero)\n",
        "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "data.fillna(0, inplace=True)\n",
        "\n",
        "# Drop rows with missing values after lagging\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Prepare features: OneHotEncode the ward numbers\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "ward_encoded = encoder.fit_transform(data['wardno'].values.reshape(-1, 1))\n",
        "\n",
        "# Prepare the year feature (number of years since 1991)\n",
        "years_since_census = data['year'] - 1991\n",
        "\n",
        "# Function to train and predict for a given target column\n",
        "def train_and_predict(target_column):\n",
        "    print(f\"\\nTraining model for '{target_column}'...\")\n",
        "    y = data[target_column].values\n",
        "\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize a StandardScaler for feature scaling\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Define models to evaluate\n",
        "    models = {\n",
        "        'Linear Regression': LinearRegression(),\n",
        "        'Decision Tree': DecisionTreeRegressor(),\n",
        "        'Random Forest': RandomForestRegressor(),\n",
        "        'Gradient Boosting': GradientBoostingRegressor(),\n",
        "        'AdaBoost': AdaBoostRegressor(),\n",
        "        'XGBoost': XGBRegressor(),\n",
        "        'LightGBM': LGBMRegressor(verbose=-1),\n",
        "        'K-Nearest Neighbors': KNeighborsRegressor(),\n",
        "        'Support Vector Regressor': SVR()\n",
        "    }\n",
        "\n",
        "    # Best model initialization\n",
        "    best_model = None\n",
        "    best_r2 = -np.inf\n",
        "\n",
        "    # Evaluate models\n",
        "    for model_name, model in models.items():\n",
        "        # Create a pipeline with feature scaling and the model\n",
        "        pipeline = Pipeline([\n",
        "            ('scaler', scaler),\n",
        "            ('model', model)\n",
        "        ])\n",
        "\n",
        "        # Fit the pipeline to the training data\n",
        "        pipeline.fit(X_train, y_train)\n",
        "\n",
        "        # Predict on the test data\n",
        "        y_pred = pipeline.predict(X_test)\n",
        "\n",
        "        # Calculate RÂ² score\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        print(f\"{model_name} R2 Score: {r2:.4f}\")\n",
        "\n",
        "        # Track the best model\n",
        "        if r2 > best_r2:\n",
        "            best_r2 = r2\n",
        "            best_model = pipeline  # Store the entire pipeline\n",
        "\n",
        "    print(f\"Best model for '{target_column}': {best_model.named_steps['model'].__class__.__name__} with R2 Score: {best_r2:.4f}\")\n",
        "\n",
        "    return best_model\n",
        "\n",
        "# Prepare feature matrix for training\n",
        "lagged_features = [f'lag_{col}' for col in tribe_target_columns]\n",
        "growth_rate_features = [f'growth_rate_{col}' for col in tribe_target_columns]\n",
        "X = np.hstack([ward_encoded, years_since_census.values.reshape(-1, 1),\n",
        "                data[lagged_features + growth_rate_features].values])\n",
        "\n",
        "# Train models for male tribes\n",
        "best_model_male_tribes = train_and_predict('maletribes')\n",
        "\n",
        "# Train models for female tribes\n",
        "best_model_female_tribes = train_and_predict('femaletribes')\n",
        "\n",
        "# New dataset to store predictions\n",
        "predicted_data_tribes = pd.DataFrame(columns=['wardno', 'year', 'predicted_maletribes', 'predicted_femaletribes'])\n",
        "\n",
        "# List of unique ward numbers\n",
        "unique_wards = data['wardno'].unique()\n",
        "\n",
        "# Prepare lists to hold predictions for each year\n",
        "predictions_2031 = []  # List to hold predictions for 2031\n",
        "predictions_2041 = []  # List to hold predictions for 2041\n",
        "\n",
        "# Prepare the features for predictions in 2031 and 2041 for male and female tribes\n",
        "for ward in unique_wards:\n",
        "    # For each ward, prepare the features for 2031\n",
        "    ward_encoded = encoder.transform([[ward]])  # One-hot encode the ward number\n",
        "    year_since_census_2031 = np.array([[2031 - 1991]])  # Feature representing 2031\n",
        "    year_since_census_2041 = np.array([[2041 - 1991]])  # Feature representing 2041\n",
        "\n",
        "    # Use the most recent data for lagged and growth rate features\n",
        "    recent_data = data[data['wardno'] == ward].iloc[-1]\n",
        "\n",
        "    # Creating lagged features and growth rate features for the latest available data\n",
        "    lagged_features = np.array([[recent_data[f'lag_{col}'] for col in tribe_target_columns]])\n",
        "    growth_rate_features = np.array([[recent_data[f'growth_rate_{col}'] for col in tribe_target_columns]])\n",
        "\n",
        "    # Combine features for prediction for 2031\n",
        "    X_male_2031 = np.hstack([ward_encoded, year_since_census_2031, lagged_features, growth_rate_features])\n",
        "    X_female_2031 = np.hstack([ward_encoded, year_since_census_2031, lagged_features, growth_rate_features])\n",
        "\n",
        "    # Ensure X_male_2031 and X_female_2031 have the same number of features as training data\n",
        "    n_features_expected = X.shape[1]  # Number of features model was trained on\n",
        "    n_features_current_male_2031 = X_male_2031.shape[1]\n",
        "    n_features_current_female_2031 = X_female_2031.shape[1]\n",
        "\n",
        "    if n_features_current_male_2031 < n_features_expected:\n",
        "        # Pad with zeros if features are missing\n",
        "        padding_male_2031 = np.zeros((1, n_features_expected - n_features_current_male_2031))\n",
        "        X_male_2031 = np.hstack([X_male_2031, padding_male_2031])\n",
        "\n",
        "    if n_features_current_female_2031 < n_features_expected:\n",
        "        # Pad with zeros if features are missing\n",
        "        padding_female_2031 = np.zeros((1, n_features_expected - n_features_current_female_2031))\n",
        "        X_female_2031 = np.hstack([X_female_2031, padding_female_2031])\n",
        "\n",
        "    # Now predict male and female tribes for this ward in 2031\n",
        "    male_tribes_2031 = best_model_male_tribes.predict(X_male_2031)\n",
        "    female_tribes_2031 = best_model_female_tribes.predict(X_female_2031)\n",
        "\n",
        "    # Store the predictions for 2031\n",
        "    predictions_2031.append({\n",
        "        'wardno': ward,\n",
        "        'year': 2031,\n",
        "        'predicted_maletribes': male_tribes_2031[0],\n",
        "        'predicted_femaletribes': female_tribes_2031[0]\n",
        "    })\n",
        "\n",
        "# After collecting all predictions for 2031, now calculate for 2041\n",
        "for ward in unique_wards:\n",
        "    # Calculate the required male and female tribes populations for 2041 (5% increase over 2031)\n",
        "    male_tribes_2031 = next((pred['predicted_maletribes'] for pred in predictions_2031 if pred['wardno'] == ward), None)\n",
        "    female_tribes_2031 = next((pred['predicted_femaletribes'] for pred in predictions_2031 if pred['wardno'] == ward), None)\n",
        "\n",
        "    if male_tribes_2031 is not None and female_tribes_2031 is not None:\n",
        "        required_male_tribes_2041 = 1.05 * male_tribes_2031\n",
        "        required_female_tribes_2041 = 1.05 * female_tribes_2031\n",
        "\n",
        "        # Store the predictions for 2041\n",
        "        predictions_2041.append({\n",
        "            'wardno': ward,\n",
        "            'year': 2041,\n",
        "            'predicted_maletribes': required_male_tribes_2041,\n",
        "            'predicted_femaletribes': required_female_tribes_2041\n",
        "        })\n",
        "\n",
        "# Combine both predictions into the final DataFrame\n",
        "predicted_data_tribes = pd.DataFrame(predictions_2031)\n",
        "predicted_data_tribes_2041 = pd.DataFrame(predictions_2041)\n",
        "\n",
        "# Concatenate the predictions for both years\n",
        "predicted_data_tribes = pd.concat([predicted_data_tribes, predicted_data_tribes_2041], ignore_index=True)\n",
        "\n",
        "# Save predictions to a CSV file\n",
        "predicted_data_tribes.to_csv('predicted_tribal_population.csv', index=False)\n",
        "\n",
        "print(predicted_data_tribes.head())  # Display the first few predictions\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cnk2TRw8VvBq",
        "outputId": "e141ea58-1f5a-468f-b40b-8ccedd9f8cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model for 'maletribes'...\n",
            "Linear Regression R2 Score: -20167867732856906681679872.0000\n",
            "Decision Tree R2 Score: 0.7466\n",
            "Random Forest R2 Score: 0.7331\n",
            "Gradient Boosting R2 Score: 0.8048\n",
            "AdaBoost R2 Score: 0.7080\n",
            "XGBoost R2 Score: 0.8244\n",
            "LightGBM R2 Score: 0.7539\n",
            "K-Nearest Neighbors R2 Score: 0.2898\n",
            "Support Vector Regressor R2 Score: -0.2332\n",
            "Best model for 'maletribes': XGBRegressor with R2 Score: 0.8244\n",
            "\n",
            "Training model for 'femaletribes'...\n",
            "Linear Regression R2 Score: -44376641761009661084958720.0000\n",
            "Decision Tree R2 Score: 0.8114\n",
            "Random Forest R2 Score: 0.7924\n",
            "Gradient Boosting R2 Score: 0.7630\n",
            "AdaBoost R2 Score: 0.5278\n",
            "XGBoost R2 Score: 0.8278\n",
            "LightGBM R2 Score: 0.8053\n",
            "K-Nearest Neighbors R2 Score: 0.3175\n",
            "Support Vector Regressor R2 Score: -0.2295\n",
            "Best model for 'femaletribes': XGBRegressor with R2 Score: 0.8278\n",
            "   wardno  year  predicted_maletribes  predicted_femaletribes\n",
            "0       1  2031            821.283875              728.394836\n",
            "1       2  2031            127.467636               75.171501\n",
            "2       3  2031            137.011154              115.247948\n",
            "3       4  2031            269.431732              245.052979\n",
            "4       5  2031            121.698006              123.847084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total Literates"
      ],
      "metadata": {
        "id": "HKE76kedfpcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('population_data.csv')  # Uncomment and specify your path\n",
        "\n",
        "# Create a target column for total literates\n",
        "target_column = 'totalliterates'  # Adjust this if your column name is different\n",
        "\n",
        "# Create lagged features and growth rates for total literates\n",
        "data[f'lag_{target_column}'] = data[target_column].shift(1)\n",
        "data[f'growth_rate_{target_column}'] = data[target_column].pct_change()\n",
        "\n",
        "# Replace Inf and NaN values with 0 in growth rates (to handle division by zero)\n",
        "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "data.fillna(0, inplace=True)\n",
        "\n",
        "# Drop rows with missing values after lagging\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Prepare features: OneHotEncode the ward numbers\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "ward_encoded = encoder.fit_transform(data['wardno'].values.reshape(-1, 1))\n",
        "\n",
        "# Prepare the year feature (number of years since 1991)\n",
        "years_since_census = data['year'] - 1991\n",
        "\n",
        "# Prepare feature matrix for training\n",
        "lagged_features = [f'lag_{target_column}']\n",
        "growth_rate_features = [f'growth_rate_{target_column}']\n",
        "X = np.hstack([ward_encoded, years_since_census.values.reshape(-1, 1),\n",
        "                data[lagged_features + growth_rate_features].values])\n",
        "\n",
        "# Function to train and predict for total literates\n",
        "def train_and_predict(target_column):\n",
        "    print(f\"\\nTraining model for '{target_column}'...\")\n",
        "    y = data[target_column].values\n",
        "\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize a StandardScaler for feature scaling\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Define models to evaluate\n",
        "    models = {\n",
        "        'Linear Regression': LinearRegression(),\n",
        "        'Decision Tree': DecisionTreeRegressor(),\n",
        "        'Random Forest': RandomForestRegressor(),\n",
        "        'Gradient Boosting': GradientBoostingRegressor(),\n",
        "        'AdaBoost': AdaBoostRegressor(),\n",
        "        'XGBoost': XGBRegressor(),\n",
        "        'LightGBM': LGBMRegressor(verbose=-1),\n",
        "        'K-Nearest Neighbors': KNeighborsRegressor(),\n",
        "        'Support Vector Regressor': SVR()\n",
        "    }\n",
        "\n",
        "    # Best model initialization\n",
        "    best_model = None\n",
        "    best_r2 = -np.inf\n",
        "\n",
        "    # Evaluate models\n",
        "    for model_name, model in models.items():\n",
        "        # Create a pipeline with feature scaling and the model\n",
        "        pipeline = Pipeline([\n",
        "            ('scaler', scaler),\n",
        "            ('model', model)\n",
        "        ])\n",
        "\n",
        "        # Fit the pipeline to the training data\n",
        "        pipeline.fit(X_train, y_train)\n",
        "\n",
        "        # Predict on the test data\n",
        "        y_pred = pipeline.predict(X_test)\n",
        "\n",
        "        # Calculate RÂ² score\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        print(f\"{model_name} R2 Score: {r2:.4f}\")\n",
        "\n",
        "        # Track the best model\n",
        "        if r2 > best_r2:\n",
        "            best_r2 = r2\n",
        "            best_model = pipeline  # Store the entire pipeline\n",
        "\n",
        "    print(f\"Best model for '{target_column}': {best_model.named_steps['model'].__class__.__name__} with R2 Score: {best_r2:.4f}\")\n",
        "\n",
        "    return best_model\n",
        "\n",
        "# Train the model for total literates\n",
        "best_model_totalliterates = train_and_predict(target_column)\n",
        "\n",
        "# New dataset to store predictions\n",
        "predicted_data_literates = pd.DataFrame(columns=['wardno', 'year', 'predicted_totalliterates'])\n",
        "\n",
        "# List of unique ward numbers\n",
        "unique_wards = data['wardno'].unique()\n",
        "\n",
        "# Prepare lists to hold predictions for each year\n",
        "predictions_2031 = []  # List to hold predictions for 2031\n",
        "predictions_2041 = []  # List to hold predictions for 2041\n",
        "\n",
        "# Prepare the features for predictions in 2031 and 2041 for total literates\n",
        "for ward in unique_wards:\n",
        "    # For each ward, prepare the features for 2031\n",
        "    ward_encoded = encoder.transform([[ward]])  # One-hot encode the ward number\n",
        "    year_since_census_2031 = np.array([[2031 - 1991]])  # Feature representing 2031\n",
        "    year_since_census_2041 = np.array([[2041 - 1991]])  # Feature representing 2041\n",
        "\n",
        "    # Use the most recent data for lagged and growth rate features\n",
        "    recent_data = data[data['wardno'] == ward].iloc[-1]\n",
        "\n",
        "    # Creating lagged features and growth rate features for the latest available data\n",
        "    lagged_features = np.array([[recent_data[f'lag_{target_column}']]])\n",
        "    growth_rate_features = np.array([[recent_data[f'growth_rate_{target_column}']]])\n",
        "\n",
        "    # Combine features for prediction for 2031\n",
        "    X_totalliterates_2031 = np.hstack([ward_encoded, year_since_census_2031, lagged_features, growth_rate_features])\n",
        "\n",
        "    # Ensure X_totalliterates_2031 has the same number of features as training data\n",
        "    n_features_expected = X.shape[1]  # Number of features model was trained on\n",
        "    n_features_current_totalliterates_2031 = X_totalliterates_2031.shape[1]\n",
        "\n",
        "    if n_features_current_totalliterates_2031 < n_features_expected:\n",
        "        # Pad with zeros if features are missing\n",
        "        padding_totalliterates_2031 = np.zeros((1, n_features_expected - n_features_current_totalliterates_2031))\n",
        "        X_totalliterates_2031 = np.hstack([X_totalliterates_2031, padding_totalliterates_2031])\n",
        "\n",
        "    # Now predict total literates for this ward in 2031\n",
        "    totalliterates_2031 = best_model_totalliterates.predict(X_totalliterates_2031)\n",
        "\n",
        "    # Store the predictions for 2031\n",
        "    predictions_2031.append({\n",
        "        'wardno': ward,\n",
        "        'year': 2031,\n",
        "        'predicted_totalliterates': totalliterates_2031[0]\n",
        "    })\n",
        "\n",
        "# After collecting all predictions for 2031, now calculate for 2041\n",
        "for ward in unique_wards:\n",
        "    # Calculate the required total literates populations for 2041 (5% increase over 2031)\n",
        "    totalliterates_2031 = next((pred['predicted_totalliterates'] for pred in predictions_2031 if pred['wardno'] == ward), None)\n",
        "\n",
        "    if totalliterates_2031 is not None:\n",
        "        required_totalliterates_2041 = 1.05 * totalliterates_2031\n",
        "\n",
        "        # Store the predictions for 2041\n",
        "        predictions_2041.append({\n",
        "            'wardno': ward,\n",
        "            'year': 2041,\n",
        "            'predicted_totalliterates': required_totalliterates_2041\n",
        "        })\n",
        "\n",
        "# Combine both predictions into the final DataFrame\n",
        "predicted_data_literates = pd.DataFrame(predictions_2031)\n",
        "predicted_data_literates_2041 = pd.DataFrame(predictions_2041)\n",
        "\n",
        "# Concatenate the predictions for both years\n",
        "predicted_data_literates = pd.concat([predicted_data_literates, predicted_data_literates_2041], ignore_index=True)\n",
        "\n",
        "# Save predictions to a CSV file\n",
        "predicted_data_literates.to_csv('predicted_total_literates.csv', index=False)\n",
        "\n",
        "print(predicted_data_literates.head())  # Display the first few predictions\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2I_pReYWsnx",
        "outputId": "aeb073d2-d401-41d3-dc33-faae5e50a78d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model for 'totalliterates'...\n",
            "Linear Regression R2 Score: -60318507297460231715422208.0000\n",
            "Decision Tree R2 Score: 0.8121\n",
            "Random Forest R2 Score: 0.7952\n",
            "Gradient Boosting R2 Score: 0.8273\n",
            "AdaBoost R2 Score: 0.7410\n",
            "XGBoost R2 Score: 0.8322\n",
            "LightGBM R2 Score: 0.7872\n",
            "K-Nearest Neighbors R2 Score: 0.4529\n",
            "Support Vector Regressor R2 Score: -0.1371\n",
            "Best model for 'totalliterates': XGBRegressor with R2 Score: 0.8322\n",
            "   wardno  year  predicted_totalliterates\n",
            "0       1  2031              34844.382812\n",
            "1       2  2031              20769.185547\n",
            "2       3  2031              17797.339844\n",
            "3       4  2031              20462.048828\n",
            "4       5  2031              14283.001953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Male Female Literates"
      ],
      "metadata": {
        "id": "jFH84CRtfs8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('population_data.csv')  # Uncomment and specify your path\n",
        "\n",
        "# List of target columns for literates\n",
        "literacy_target_columns = ['totalliterates', 'maleliterates', 'femaleliterates']\n",
        "\n",
        "# Create lagged features and growth rates for each target column\n",
        "for col in literacy_target_columns:\n",
        "    data[f'lag_{col}'] = data[col].shift(1)\n",
        "    data[f'growth_rate_{col}'] = data[col].pct_change()\n",
        "\n",
        "# Replace Inf and NaN values with 0 in growth rates (to handle division by zero)\n",
        "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "data.fillna(0, inplace=True)\n",
        "\n",
        "# Drop rows with missing values after lagging\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Prepare features: OneHotEncode the ward numbers\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "ward_encoded = encoder.fit_transform(data['wardno'].values.reshape(-1, 1))\n",
        "\n",
        "# Prepare the year feature (number of years since 1991)\n",
        "years_since_census = data['year'] - 1991\n",
        "\n",
        "# Function to train and predict for a given target column\n",
        "def train_and_predict(target_column):\n",
        "    print(f\"\\nTraining model for '{target_column}'...\")\n",
        "    y = data[target_column].values\n",
        "\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize a StandardScaler for feature scaling\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Define models to evaluate\n",
        "    models = {\n",
        "        'Linear Regression': LinearRegression(),\n",
        "        'Decision Tree': DecisionTreeRegressor(),\n",
        "        'Random Forest': RandomForestRegressor(),\n",
        "        'Gradient Boosting': GradientBoostingRegressor(),\n",
        "        'AdaBoost': AdaBoostRegressor(),\n",
        "        'XGBoost': XGBRegressor(),\n",
        "        'LightGBM': LGBMRegressor(verbose=-1),\n",
        "        'K-Nearest Neighbors': KNeighborsRegressor(),\n",
        "        'Support Vector Regressor': SVR()\n",
        "    }\n",
        "\n",
        "    # Best model initialization\n",
        "    best_model = None\n",
        "    best_r2 = -np.inf\n",
        "\n",
        "    # Evaluate models\n",
        "    for model_name, model in models.items():\n",
        "        # Create a pipeline with feature scaling and the model\n",
        "        pipeline = Pipeline([\n",
        "            ('scaler', scaler),\n",
        "            ('model', model)\n",
        "        ])\n",
        "\n",
        "        # Fit the pipeline to the training data\n",
        "        pipeline.fit(X_train, y_train)\n",
        "\n",
        "        # Predict on the test data\n",
        "        y_pred = pipeline.predict(X_test)\n",
        "\n",
        "        # Calculate RÂ² score\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        print(f\"{model_name} R2 Score: {r2:.4f}\")\n",
        "\n",
        "        # Track the best model\n",
        "        if r2 > best_r2:\n",
        "            best_r2 = r2\n",
        "            best_model = pipeline  # Store the entire pipeline\n",
        "\n",
        "    print(f\"Best model for '{target_column}': {best_model.named_steps['model'].__class__.__name__} with R2 Score: {best_r2:.4f}\")\n",
        "\n",
        "    return best_model\n",
        "\n",
        "# Prepare feature matrix for training\n",
        "lagged_features = [f'lag_{col}' for col in literacy_target_columns]\n",
        "growth_rate_features = [f'growth_rate_{col}' for col in literacy_target_columns]\n",
        "X = np.hstack([ward_encoded, years_since_census.values.reshape(-1, 1),\n",
        "                data[lagged_features + growth_rate_features].values])\n",
        "\n",
        "# Train models for male literates\n",
        "best_model_male_literates = train_and_predict('maleliterates')\n",
        "\n",
        "# Train models for female literates\n",
        "best_model_female_literates = train_and_predict('femaleliterates')\n",
        "\n",
        "# New dataset to store predictions\n",
        "predicted_data_literates = pd.DataFrame(columns=['wardno', 'year', 'predicted_maleliterates', 'predicted_femaleliterates'])\n",
        "\n",
        "# List of unique ward numbers\n",
        "unique_wards = data['wardno'].unique()\n",
        "\n",
        "# Prepare lists to hold predictions for each year\n",
        "predictions_2031 = []  # List to hold predictions for 2031\n",
        "predictions_2041 = []  # List to hold predictions for 2041\n",
        "\n",
        "# Prepare the features for predictions in 2031 and 2041 for male and female literates\n",
        "for ward in unique_wards:\n",
        "    # For each ward, prepare the features for 2031\n",
        "    ward_encoded = encoder.transform([[ward]])  # One-hot encode the ward number\n",
        "    year_since_census_2031 = np.array([[2031 - 1991]])  # Feature representing 2031\n",
        "    year_since_census_2041 = np.array([[2041 - 1991]])  # Feature representing 2041\n",
        "\n",
        "    # Use the most recent data for lagged and growth rate features\n",
        "    recent_data = data[data['wardno'] == ward].iloc[-1]\n",
        "\n",
        "    # Creating lagged features and growth rate features for the latest available data\n",
        "    lagged_features = np.array([[recent_data[f'lag_{col}'] for col in literacy_target_columns]])\n",
        "    growth_rate_features = np.array([[recent_data[f'growth_rate_{col}'] for col in literacy_target_columns]])\n",
        "\n",
        "    # Combine features for prediction for 2031\n",
        "    X_male_2031 = np.hstack([ward_encoded, year_since_census_2031, lagged_features, growth_rate_features])\n",
        "    X_female_2031 = np.hstack([ward_encoded, year_since_census_2031, lagged_features, growth_rate_features])\n",
        "\n",
        "    # Ensure X_male_2031 and X_female_2031 have the same number of features as training data\n",
        "    n_features_expected = X.shape[1]  # Number of features model was trained on\n",
        "    n_features_current_male_2031 = X_male_2031.shape[1]\n",
        "    n_features_current_female_2031 = X_female_2031.shape[1]\n",
        "\n",
        "    if n_features_current_male_2031 < n_features_expected:\n",
        "        # Pad with zeros if features are missing\n",
        "        padding_male_2031 = np.zeros((1, n_features_expected - n_features_current_male_2031))\n",
        "        X_male_2031 = np.hstack([X_male_2031, padding_male_2031])\n",
        "\n",
        "    if n_features_current_female_2031 < n_features_expected:\n",
        "        # Pad with zeros if features are missing\n",
        "        padding_female_2031 = np.zeros((1, n_features_expected - n_features_current_female_2031))\n",
        "        X_female_2031 = np.hstack([X_female_2031, padding_female_2031])\n",
        "\n",
        "    # Now predict male and female literates for this ward in 2031\n",
        "    male_literates_2031 = best_model_male_literates.predict(X_male_2031)\n",
        "    female_literates_2031 = best_model_female_literates.predict(X_female_2031)\n",
        "\n",
        "    # Store the predictions for 2031\n",
        "    predictions_2031.append({\n",
        "        'wardno': ward,\n",
        "        'year': 2031,\n",
        "        'predicted_maleliterates': male_literates_2031[0],\n",
        "        'predicted_femaleliterates': female_literates_2031[0]\n",
        "    })\n",
        "\n",
        "# After collecting all predictions for 2031, now calculate for 2041\n",
        "for ward in unique_wards:\n",
        "    # Calculate the required male and female literates populations for 2041 (5% increase over 2031)\n",
        "    male_literates_2031 = next((pred['predicted_maleliterates'] for pred in predictions_2031 if pred['wardno'] == ward), None)\n",
        "    female_literates_2031 = next((pred['predicted_femaleliterates'] for pred in predictions_2031 if pred['wardno'] == ward), None)\n",
        "\n",
        "    if male_literates_2031 is not None and female_literates_2031 is not None:\n",
        "        required_male_literates_2041 = 1.05 * male_literates_2031\n",
        "        required_female_literates_2041 = 1.05 * female_literates_2031\n",
        "\n",
        "        # Store the predictions for 2041\n",
        "        predictions_2041.append({\n",
        "            'wardno': ward,\n",
        "            'year': 2041,\n",
        "            'predicted_maleliterates': required_male_literates_2041,\n",
        "            'predicted_femaleliterates': required_female_literates_2041\n",
        "        })\n",
        "\n",
        "# Convert predictions lists to DataFrames\n",
        "predictions_2031_df = pd.DataFrame(predictions_2031)\n",
        "predictions_2041_df = pd.DataFrame(predictions_2041)\n",
        "\n",
        "# Concatenate predictions DataFrames\n",
        "final_predictions = pd.concat([predictions_2031_df, predictions_2041_df], ignore_index=True)\n",
        "\n",
        "# Save to CSV\n",
        "final_predictions.to_csv('predicted_male_female_literates_2031_2041.csv', index=False)\n",
        "\n",
        "print(\"Predictions for male and female literates saved to 'predicted_literates_2031_2041.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvilYHh6a5EO",
        "outputId": "1059ec12-bbb4-4f56-f66f-67fc3cf71a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model for 'maleliterates'...\n",
            "Linear Regression R2 Score: -69241624542363208847982592.0000\n",
            "Decision Tree R2 Score: 0.7632\n",
            "Random Forest R2 Score: 0.7935\n",
            "Gradient Boosting R2 Score: 0.8281\n",
            "AdaBoost R2 Score: 0.7161\n",
            "XGBoost R2 Score: 0.8156\n",
            "LightGBM R2 Score: 0.7729\n",
            "K-Nearest Neighbors R2 Score: 0.4837\n",
            "Support Vector Regressor R2 Score: -0.1462\n",
            "Best model for 'maleliterates': GradientBoostingRegressor with R2 Score: 0.8281\n",
            "\n",
            "Training model for 'femaleliterates'...\n",
            "Linear Regression R2 Score: -82820569146318825338175488.0000\n",
            "Decision Tree R2 Score: 0.8227\n",
            "Random Forest R2 Score: 0.8029\n",
            "Gradient Boosting R2 Score: 0.8341\n",
            "AdaBoost R2 Score: 0.7424\n",
            "XGBoost R2 Score: 0.8446\n",
            "LightGBM R2 Score: 0.7892\n",
            "K-Nearest Neighbors R2 Score: 0.4723\n",
            "Support Vector Regressor R2 Score: -0.1253\n",
            "Best model for 'femaleliterates': XGBRegressor with R2 Score: 0.8446\n",
            "Predictions for male and female literates saved to 'predicted_literates_2031_2041.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total Illiterates"
      ],
      "metadata": {
        "id": "-NOYm0u_fw3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('population_data.csv')  # Uncomment and specify your path\n",
        "\n",
        "# Create a target column for total illiterates\n",
        "target_column = 'totalilliterates'  # Adjust this if your column name is different\n",
        "\n",
        "# Create lagged features and growth rates for total illiterates\n",
        "data[f'lag_{target_column}'] = data[target_column].shift(1)\n",
        "data[f'growth_rate_{target_column}'] = data[target_column].pct_change()\n",
        "\n",
        "# Replace Inf and NaN values with 0 in growth rates (to handle division by zero)\n",
        "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "data.fillna(0, inplace=True)\n",
        "\n",
        "# Drop rows with missing values after lagging\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Prepare features: OneHotEncode the ward numbers\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "ward_encoded = encoder.fit_transform(data['wardno'].values.reshape(-1, 1))\n",
        "\n",
        "# Prepare the year feature (number of years since 1991)\n",
        "years_since_census = data['year'] - 1991\n",
        "\n",
        "# Prepare feature matrix for training\n",
        "lagged_features = [f'lag_{target_column}']\n",
        "growth_rate_features = [f'growth_rate_{target_column}']\n",
        "X = np.hstack([ward_encoded, years_since_census.values.reshape(-1, 1),\n",
        "                data[lagged_features + growth_rate_features].values])\n",
        "\n",
        "# Function to train and predict for total illiterates\n",
        "def train_and_predict(target_column):\n",
        "    print(f\"\\nTraining model for '{target_column}'...\")\n",
        "    y = data[target_column].values\n",
        "\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize a StandardScaler for feature scaling\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Define models to evaluate\n",
        "    models = {\n",
        "        'Linear Regression': LinearRegression(),\n",
        "        'Decision Tree': DecisionTreeRegressor(),\n",
        "        'Random Forest': RandomForestRegressor(),\n",
        "        'Gradient Boosting': GradientBoostingRegressor(),\n",
        "        'AdaBoost': AdaBoostRegressor(),\n",
        "        'XGBoost': XGBRegressor(),\n",
        "        'LightGBM': LGBMRegressor(verbose=-1),\n",
        "        'K-Nearest Neighbors': KNeighborsRegressor(),\n",
        "        'Support Vector Regressor': SVR()\n",
        "    }\n",
        "\n",
        "    # Best model initialization\n",
        "    best_model = None\n",
        "    best_r2 = -np.inf\n",
        "\n",
        "    # Evaluate models\n",
        "    for model_name, model in models.items():\n",
        "        # Create a pipeline with feature scaling and the model\n",
        "        pipeline = Pipeline([\n",
        "            ('scaler', scaler),\n",
        "            ('model', model)\n",
        "        ])\n",
        "\n",
        "        # Fit the pipeline to the training data\n",
        "        pipeline.fit(X_train, y_train)\n",
        "\n",
        "        # Predict on the test data\n",
        "        y_pred = pipeline.predict(X_test)\n",
        "\n",
        "        # Calculate RÂ² score\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        print(f\"{model_name} R2 Score: {r2:.4f}\")\n",
        "\n",
        "        # Track the best model\n",
        "        if r2 > best_r2:\n",
        "            best_r2 = r2\n",
        "            best_model = pipeline  # Store the entire pipeline\n",
        "\n",
        "    print(f\"Best model for '{target_column}': {best_model.named_steps['model'].__class__.__name__} with R2 Score: {best_r2:.4f}\")\n",
        "\n",
        "    return best_model\n",
        "\n",
        "# Train the model for total illiterates\n",
        "best_model_totalillerates = train_and_predict(target_column)\n",
        "\n",
        "# New dataset to store predictions\n",
        "predicted_data_illiterates = pd.DataFrame(columns=['wardno', 'year', 'predicted_totalillerates'])\n",
        "\n",
        "# List of unique ward numbers\n",
        "unique_wards = data['wardno'].unique()\n",
        "\n",
        "# Prepare lists to hold predictions for each year\n",
        "predictions_2031 = []  # List to hold predictions for 2031\n",
        "predictions_2041 = []  # List to hold predictions for 2041\n",
        "\n",
        "# Prepare the features for predictions in 2031 and 2041 for total illiterates\n",
        "for ward in unique_wards:\n",
        "    # For each ward, prepare the features for 2031\n",
        "    ward_encoded = encoder.transform([[ward]])  # One-hot encode the ward number\n",
        "    year_since_census_2031 = np.array([[2031 - 1991]])  # Feature representing 2031\n",
        "    year_since_census_2041 = np.array([[2041 - 1991]])  # Feature representing 2041\n",
        "\n",
        "    # Use the most recent data for lagged and growth rate features\n",
        "    recent_data = data[data['wardno'] == ward].iloc[-1]\n",
        "\n",
        "    # Creating lagged features and growth rate features for the latest available data\n",
        "    lagged_features = np.array([[recent_data[f'lag_{target_column}']]])\n",
        "    growth_rate_features = np.array([[recent_data[f'growth_rate_{target_column}']]])\n",
        "\n",
        "    # Combine features for prediction for 2031\n",
        "    X_totalillerates_2031 = np.hstack([ward_encoded, year_since_census_2031, lagged_features, growth_rate_features])\n",
        "\n",
        "    # Ensure X_totalillerates_2031 has the same number of features as training data\n",
        "    n_features_expected = X.shape[1]  # Number of features model was trained on\n",
        "    n_features_current_totalillerates_2031 = X_totalillerates_2031.shape[1]\n",
        "\n",
        "    if n_features_current_totalillerates_2031 < n_features_expected:\n",
        "        # Pad with zeros if features are missing\n",
        "        padding_totalillerates_2031 = np.zeros((1, n_features_expected - n_features_current_totalillerates_2031))\n",
        "        X_totalillerates_2031 = np.hstack([X_totalillerates_2031, padding_totalillerates_2031])\n",
        "\n",
        "    # Now predict total illiterates for this ward in 2031\n",
        "    totalillerates_2031 = best_model_totalillerates.predict(X_totalillerates_2031)\n",
        "\n",
        "    # Store the predictions for 2031\n",
        "    predictions_2031.append({\n",
        "        'wardno': ward,\n",
        "        'year': 2031,\n",
        "        'predicted_totalillerates': totalillerates_2031[0]\n",
        "    })\n",
        "\n",
        "# After collecting all predictions for 2031, now calculate for 2041\n",
        "for ward in unique_wards:\n",
        "    # Calculate the required total illiterates populations for 2041 (5% increase over 2031)\n",
        "    totalillerates_2031 = next((pred['predicted_totalillerates'] for pred in predictions_2031 if pred['wardno'] == ward), None)\n",
        "\n",
        "    if totalillerates_2031 is not None:\n",
        "        required_totalillerates_2041 = 1.05 * totalillerates_2031\n",
        "\n",
        "        # Store the predictions for 2041\n",
        "        predictions_2041.append({\n",
        "            'wardno': ward,\n",
        "            'year': 2041,\n",
        "            'predicted_totalillerates': required_totalillerates_2041\n",
        "        })\n",
        "\n",
        "# Combine both predictions into the final DataFrame\n",
        "predicted_data_illiterates = pd.DataFrame(predictions_2031)\n",
        "predicted_data_illiterates_2041 = pd.DataFrame(predictions_2041)\n",
        "\n",
        "# Concatenate the predictions for both years\n",
        "predicted_data_illiterates = pd.concat([predicted_data_illiterates, predicted_data_illiterates_2041], ignore_index=True)\n",
        "\n",
        "# Save predictions to a CSV file\n",
        "predicted_data_illiterates.to_csv('predicted_total_illiterates.csv', index=False)\n",
        "\n",
        "print(predicted_data_illiterates.head())  # Display the first few predictions\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DxWQ_r1cW_J",
        "outputId": "c81379e7-9574-4592-df5b-a33f38016b9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model for 'totalilliterates'...\n",
            "Linear Regression R2 Score: -79177981839695226014269440.0000\n",
            "Decision Tree R2 Score: 0.8458\n",
            "Random Forest R2 Score: 0.8199\n",
            "Gradient Boosting R2 Score: 0.8745\n",
            "AdaBoost R2 Score: 0.7281\n",
            "XGBoost R2 Score: 0.8457\n",
            "LightGBM R2 Score: 0.8098\n",
            "K-Nearest Neighbors R2 Score: 0.3777\n",
            "Support Vector Regressor R2 Score: -0.0939\n",
            "Best model for 'totalilliterates': GradientBoostingRegressor with R2 Score: 0.8745\n",
            "   wardno  year  predicted_totalillerates\n",
            "0       1  2031               9079.909330\n",
            "1       2  2031               5880.028647\n",
            "2       3  2031               5064.622170\n",
            "3       4  2031               4179.939781\n",
            "4       5  2031               4266.239259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Male Female Illiterates"
      ],
      "metadata": {
        "id": "yWfcDRmYf0VD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('population_data.csv')  # Uncomment and specify your path\n",
        "\n",
        "# List of target columns for illiterates\n",
        "illiteracy_target_columns = ['totalilliterates', 'maleilliterates', 'femaleilliterates']\n",
        "\n",
        "# Create lagged features and growth rates for each target column\n",
        "for col in illiteracy_target_columns:\n",
        "    data[f'lag_{col}'] = data[col].shift(1)\n",
        "    data[f'growth_rate_{col}'] = data[col].pct_change()\n",
        "\n",
        "# Replace Inf and NaN values with 0 in growth rates (to handle division by zero)\n",
        "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "data.fillna(0, inplace=True)\n",
        "\n",
        "# Drop rows with missing values after lagging\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Prepare features: OneHotEncode the ward numbers\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "ward_encoded = encoder.fit_transform(data['wardno'].values.reshape(-1, 1))\n",
        "\n",
        "# Prepare the year feature (number of years since 1991)\n",
        "years_since_census = data['year'] - 1991\n",
        "\n",
        "# Function to train and predict for a given target column\n",
        "def train_and_predict(target_column):\n",
        "    print(f\"\\nTraining model for '{target_column}'...\")\n",
        "    y = data[target_column].values\n",
        "\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize a StandardScaler for feature scaling\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Define models to evaluate\n",
        "    models = {\n",
        "        'Linear Regression': LinearRegression(),\n",
        "        'Decision Tree': DecisionTreeRegressor(),\n",
        "        'Random Forest': RandomForestRegressor(),\n",
        "        'Gradient Boosting': GradientBoostingRegressor(),\n",
        "        'AdaBoost': AdaBoostRegressor(),\n",
        "        'XGBoost': XGBRegressor(),\n",
        "        'LightGBM': LGBMRegressor(verbose=-1),\n",
        "        'K-Nearest Neighbors': KNeighborsRegressor(),\n",
        "        'Support Vector Regressor': SVR()\n",
        "    }\n",
        "\n",
        "    # Best model initialization\n",
        "    best_model = None\n",
        "    best_r2 = -np.inf\n",
        "\n",
        "    # Evaluate models\n",
        "    for model_name, model in models.items():\n",
        "        # Create a pipeline with feature scaling and the model\n",
        "        pipeline = Pipeline([\n",
        "            ('scaler', scaler),\n",
        "            ('model', model)\n",
        "        ])\n",
        "\n",
        "        # Fit the pipeline to the training data\n",
        "        pipeline.fit(X_train, y_train)\n",
        "\n",
        "        # Predict on the test data\n",
        "        y_pred = pipeline.predict(X_test)\n",
        "\n",
        "        # Calculate RÂ² score\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        print(f\"{model_name} R2 Score: {r2:.4f}\")\n",
        "\n",
        "        # Track the best model\n",
        "        if r2 > best_r2:\n",
        "            best_r2 = r2\n",
        "            best_model = pipeline  # Store the entire pipeline\n",
        "\n",
        "    print(f\"Best model for '{target_column}': {best_model.named_steps['model'].__class__.__name__} with R2 Score: {best_r2:.4f}\")\n",
        "\n",
        "    return best_model\n",
        "\n",
        "# Prepare feature matrix for training\n",
        "lagged_features = [f'lag_{col}' for col in illiteracy_target_columns]\n",
        "growth_rate_features = [f'growth_rate_{col}' for col in illiteracy_target_columns]\n",
        "X = np.hstack([ward_encoded, years_since_census.values.reshape(-1, 1),\n",
        "                data[lagged_features + growth_rate_features].values])\n",
        "\n",
        "# Train models for male illiterates\n",
        "best_model_male_illiterates = train_and_predict('maleilliterates')\n",
        "\n",
        "# Train models for female illiterates\n",
        "best_model_female_illiterates = train_and_predict('femaleilliterates')\n",
        "\n",
        "# New dataset to store predictions\n",
        "predicted_data_illiterates = pd.DataFrame(columns=['wardno', 'year', 'predicted_maleilliterates', 'predicted_femaleilliterates'])\n",
        "\n",
        "# List of unique ward numbers\n",
        "unique_wards = data['wardno'].unique()\n",
        "\n",
        "# Prepare lists to hold predictions for each year\n",
        "predictions_2031 = []  # List to hold predictions for 2031\n",
        "predictions_2041 = []  # List to hold predictions for 2041\n",
        "\n",
        "# Prepare the features for predictions in 2031 and 2041 for male and female illiterates\n",
        "for ward in unique_wards:\n",
        "    # For each ward, prepare the features for 2031\n",
        "    ward_encoded = encoder.transform([[ward]])  # One-hot encode the ward number\n",
        "    year_since_census_2031 = np.array([[2031 - 1991]])  # Feature representing 2031\n",
        "    year_since_census_2041 = np.array([[2041 - 1991]])  # Feature representing 2041\n",
        "\n",
        "    # Use the most recent data for lagged and growth rate features\n",
        "    recent_data = data[data['wardno'] == ward].iloc[-1]\n",
        "\n",
        "    # Creating lagged features and growth rate features for the latest available data\n",
        "    lagged_features = np.array([[recent_data[f'lag_{col}'] for col in illiteracy_target_columns]])\n",
        "    growth_rate_features = np.array([[recent_data[f'growth_rate_{col}'] for col in illiteracy_target_columns]])\n",
        "\n",
        "    # Combine features for prediction for 2031\n",
        "    X_male_2031 = np.hstack([ward_encoded, year_since_census_2031, lagged_features, growth_rate_features])\n",
        "    X_female_2031 = np.hstack([ward_encoded, year_since_census_2031, lagged_features, growth_rate_features])\n",
        "\n",
        "    # Ensure X_male_2031 and X_female_2031 have the same number of features as training data\n",
        "    n_features_expected = X.shape[1]  # Number of features model was trained on\n",
        "    n_features_current_male_2031 = X_male_2031.shape[1]\n",
        "    n_features_current_female_2031 = X_female_2031.shape[1]\n",
        "\n",
        "    if n_features_current_male_2031 < n_features_expected:\n",
        "        # Pad with zeros if features are missing\n",
        "        padding_male_2031 = np.zeros((1, n_features_expected - n_features_current_male_2031))\n",
        "        X_male_2031 = np.hstack([X_male_2031, padding_male_2031])\n",
        "\n",
        "    if n_features_current_female_2031 < n_features_expected:\n",
        "        # Pad with zeros if features are missing\n",
        "        padding_female_2031 = np.zeros((1, n_features_expected - n_features_current_female_2031))\n",
        "        X_female_2031 = np.hstack([X_female_2031, padding_female_2031])\n",
        "\n",
        "    # Now predict male and female illiterates for this ward in 2031\n",
        "    male_illiterates_2031 = best_model_male_illiterates.predict(X_male_2031)\n",
        "    female_illiterates_2031 = best_model_female_illiterates.predict(X_female_2031)\n",
        "\n",
        "    # Store the predictions for 2031\n",
        "    predictions_2031.append({\n",
        "        'wardno': ward,\n",
        "        'year': 2031,\n",
        "        'predicted_maleilliterates': male_illiterates_2031[0],\n",
        "        'predicted_femaleilliterates': female_illiterates_2031[0]\n",
        "    })\n",
        "\n",
        "# After collecting all predictions for 2031, now calculate for 2041\n",
        "for ward in unique_wards:\n",
        "    # Calculate the required male and female illiterates populations for 2041 (5% increase over 2031)\n",
        "    male_illiterates_2031 = next((pred['predicted_maleilliterates'] for pred in predictions_2031 if pred['wardno'] == ward), None)\n",
        "    female_illiterates_2031 = next((pred['predicted_femaleilliterates'] for pred in predictions_2031 if pred['wardno'] == ward), None)\n",
        "\n",
        "    if male_illiterates_2031 is not None and female_illiterates_2031 is not None:\n",
        "        required_male_illiterates_2041 = 1.05 * male_illiterates_2031\n",
        "        required_female_illiterates_2041 = 1.05 * female_illiterates_2031\n",
        "\n",
        "        # Store the predictions for 2041\n",
        "        predictions_2041.append({\n",
        "            'wardno': ward,\n",
        "            'year': 2041,\n",
        "            'predicted_maleilliterates': required_male_illiterates_2041,\n",
        "            'predicted_femaleilliterates': required_female_illiterates_2041\n",
        "        })\n",
        "\n",
        "# Convert predictions to DataFrame\n",
        "predicted_data_illiterates = pd.DataFrame(predictions_2041)\n",
        "\n",
        "# Save the predicted data\n",
        "predicted_data_illiterates.to_csv('predicted_illiterates_data.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4iaFtqndlT1",
        "outputId": "724f0474-42e4-4858-b0b3-9c857b9a3485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model for 'maleilliterates'...\n",
            "Linear Regression R2 Score: -52681384278966728130560.0000\n",
            "Decision Tree R2 Score: 0.8613\n",
            "Random Forest R2 Score: 0.8279\n",
            "Gradient Boosting R2 Score: 0.8846\n",
            "AdaBoost R2 Score: 0.7650\n",
            "XGBoost R2 Score: 0.8652\n",
            "LightGBM R2 Score: 0.8190\n",
            "K-Nearest Neighbors R2 Score: 0.3810\n",
            "Support Vector Regressor R2 Score: -0.1175\n",
            "Best model for 'maleilliterates': GradientBoostingRegressor with R2 Score: 0.8846\n",
            "\n",
            "Training model for 'femaleilliterates'...\n",
            "Linear Regression R2 Score: -69813635307596295169900544.0000\n",
            "Decision Tree R2 Score: 0.8180\n",
            "Random Forest R2 Score: 0.8191\n",
            "Gradient Boosting R2 Score: 0.8729\n",
            "AdaBoost R2 Score: 0.7172\n",
            "XGBoost R2 Score: 0.8357\n",
            "LightGBM R2 Score: 0.8060\n",
            "K-Nearest Neighbors R2 Score: 0.3896\n",
            "Support Vector Regressor R2 Score: -0.0861\n",
            "Best model for 'femaleilliterates': GradientBoostingRegressor with R2 Score: 0.8729\n"
          ]
        }
      ]
    }
  ]
}